.TH "HaMMLET" "1" "" "" ""
.SH NAME
.PP
\f[B]HaMMLET\f[] \- Fast Bayesian Inference for Hidden Markov Models
using Dynamic Haar Wavelet Compression.
.SH DESCRIPTION
.PP
HaMMLET is a fast Forward\-Backward Gibbs (FBG) sampler for Bayesian
HMM.
It also implements alternative sampling schemes (currently supported:
Mixture Model sampling).
Given numerical input data and prior parameters, it outputs a full
distribution of latent HMM states for each position, integrating over
the entire parameter space.
In modern applications, such as the detection of copy\-number variants
(CNV) using whole\-genome sequencing data, the input sizes are on the
order of millions to billions of data points.
To avoid prohibitively long running times and slow convergence, HaMMLET
uses the Haar wavelet transform to dynamically compress the data into
blocks of sufficient statistics, based on the lowest noise estimate in
each iteration of the Gibbs sampler.
.PP
When using HaMMLET, please cite the following paper (a BibTeX file is
provided in doc/hammlet.bib):
.RS
.PP
Wiedenhoeft, J., Brugel, E., & Schliep, A.
(2016).
"Fast Bayesian Inference of Copy Number Variants using Hidden Markov
Models with Wavelet Compression".
PLOS Computational Biology, 12(5), e1004871.
http://doi.org/10.1371/journal.pcbi.1004871.
This paper was selected for oral presentation at RECOMB 2016.
.RE
.SH USAGE EXAMPLE
.PP
\f[B]hammlet \-f data.csv \-s 3 \-a \-R 0\f[]
.PP
Run HaMMLET on input file \f[B]data.csv\f[], using a \f[B]3\f[]\-state
model with \f[B]automatic priors\f[] and random\-number seed \f[B]0\f[]
for reproducibility.
This outputs the state marginals to \f[B]hammlet\-marginals.csv\f[].
.PP
\f[B]cat data.csv | hammlet \-a \-R 32 \-s 8 \-i M 100 0 F 200 5 \-t 1
10 \-O blocks compression marginals \-o result\- .csv\f[]
.PP
This reads data from STDIN.
Using a model with \f[B]automatic\f[] emission priors with standard
parameters and a random seed of \f[B]32\f[] for reproducibility, HaMMLET
inferes an \f[B]8\f[]\-state segmentation.
Sampling of state sequences is done by first running \f[B]mixture
sampling\f[] for \f[B]100\f[] iterations, \f[B]none\f[] of which is
recorded, followed by \f[B]Forward\-Backward Gibbs sampling (FBG)\f[]
for \f[B]200\f[] iterations, recording every \f[B]fifth\f[] of them.
This is done using prior \f[B]transition\f[] weights of \f[B]10\f[] for
self\-transitions, and \f[B]1\f[] for transition between different
states.
The output consists of the sizes of \f[B]blocks\f[] for each iteration,
the \f[B]compression\f[] ratios as well as the state \f[B]marginals\f[].
The output files are \f[B]result\-blocks.csv\f[],
\f[B]result.compression.csv\f[], and \f[B]result\-marginals.csv\f[],
respectively (notice the space \f[B]\-o\f[] takes two arguments, prefix
and suffix).
.SH OPTIONS
.TP
.B \-h | \-help
Display a friendly help message.
.RS
.RE
.TP
.B \-v | \-verbose
Print information to \f[I]STDOUT\f[] during run\-time.
.RS
.RE
.TP
.B \-g | \-arguments
Print arguments.
For each flag, print an asterisk if it was set by the user, as well as
the parameters being used.
If the flag was not set, these are the default parameters.
.RS
.RE
.SS INPUT AND OUTPUT
.PP
HaMMLET reads the observed emission values as a stream of
whitespace\-separated numeric values from \f[I]STDIN\f[], unless
\f[B]\-f\f[] is specified.
Linebreaks are treated as whitespace, and no formatting such as CSV is
interpreted.
For multivariate models, the dimensions of each position are filled in
increasing order, after which dimensions for the next position are
filled.
If the number of input values is not a multiple of the number of
dimensions (see \f[B]\-s\f[] option), an exception is thrown.
.PP
The output consists of a CSV file representing a run\-length encoded
version of the state marginals.
The first column represents the length of a segment (number of input
positions), and subsequent columns represent the recorded counts for
each state, in increasing order of state number.
.TP
.B \-f \f[I]FILE\f[] | \-input\-file \f[I]FILE\f[]
Read input data from \f[I]FILE\f[] instead of \f[I]STDIN\f[].
.RS
.RE
.TP
.B \-o \f[I]PREFIX\f[] \f[I]SUFFIX\f[] | \-output\-prefix
\f[I]PREFIX\f[] \f[I]SUFFIX\f[]
The prefix and suffix for the output file paths.
Output files names are created by adding a short descriptor, e.g.
\f[I]PREFIX\f[]marginals\f[I]SUFFIX\f[] for the file containing the
marginal state distribution; for additional files, see the \f[B]\-O\f[]
option for details.
If this option is not set, the behavior depends on the \-c/\-f flags: If
\-c is set, \-o \f[B]hammlet\f[] \f[B]\&.csv\f[] is used; if \-f
\f[I]FILENAME.EXT\f[] is provided, \-o \f[B]FILENAME\-\f[]
\f[B]\&.EXT\f[] is used instead.
.RS
.RE
.TP
.B \-O \f[I]TYPE\f[] ... | \-output\-data \f[I]TYPE\f[] ...
Specify a list of data types to be output in addition to the marginals.
This only applies to recorded iterations as specified using
\f[B]\-i\f[].
It may contain any of the following:
.RS
.TP
.B B | blocks
Output the block structure (sizes of all blocks) created by dynamic
compression, separated by whitespace.
.RS
.RE
.TP
.B C | compression
Output the compression ratio for each iteration.
.RS
.RE
.TP
.B D | mapping
Lines represent states in ascending order.
Columns represent data dimensions.
Entries represent the index of emission distributions for each state and
data dimension.
.RS
.RE
.TP
.B G | segments
Output the number of segments in each iteration, as well as the number
of values used to store the compressed marginals (for diagnostic
purposes).
.RS
.RE
.TP
.B P | parameters
Output the emission parameters for each state in increasing order of
state number, separated by tabs.
.RS
.RE
.TP
.B S | sequences
Output each state sequence individually, one per line, separated by
whitespace, using run\-length encoding of the form
\f[I]LENGTH\f[]:\f[I]STATE\f[].
.RS
.RE
.RE
.TP
.B \-w | \-overwrite
Overwrite existing output files.
If \f[B]\-w\f[] is not provided and an output file already exists, an
exception is thrown.
.RS
.RE
.SS MODEL SPECIFICATIONS
.TP
.B \-s \f[I]PARAM\f[] | \-states \f[I]PARAM\f[]
Definition of hidden states.
\f[I]PARAM\f[] may take the following forms [Default: \f[B]3\f[]]:
.RS
.TP
.B \f[I]NRSTATES\f[]
The typical, simple case of an HMM: Given a single unsigned integer
\f[I]NRSTATES\f[], the data is assumed to be one\-dimensional and
generated from this many hidden states.
.RS
.RE
.TP
.B \f[I]MAPPING\f[] \f[I]NRDIST\f[] \f[I]NRDIM\f[] \f[I]LIST\f[]
State definitions in the form of a \f[I]MAPPING\f[].
The data has \f[I]NRDIM\f[] dimensions, and there are \f[I]NRDIST\f[]
different emission distributions.
If \f[I]NRDIM\f[] is not provided, it defaults to \f[B]1\f[].
A state is defined as a vector S of size \f[I]NRDIM\f[], where S[i]
denotes that the i\-th dimension of an emission sampled from this state
was generated from the S[i]\-th emission distribution.
For instance, if a 3\-dimensional data point is assigned to a state with
mapping S=[1 1 2], its first two dimensions are assumed to be generated
by emission distribution 1, and its third dimension by emission
distribution 2.
The following \f[I]MAPPING\f[] schemes are supported:
.RS
.TP
.B S | shared
All values at a given data position are assumed to be generated by the
same emission distribution across \f[I]NRDIM\f[] data dimensions.
\f[I]NRDIM\f[] defaults to 1, and the number of states equals
\f[I]NRDIST\f[].
.RS
.RE
.TP
.B C | combination
States express all possible combinations of emission distributions,
resulting in \f[I]NRPARAMS\f[]^\f[I]NRDIM\f[] different states.
For instance, \f[B]\-s C 2 3\f[] generates 2^3=8 state mappings: (1 1
1), (1 1 2), (1 2 1), (1 2 2), (2 1 1), (2 1 2), (2 2 1), and (2 2 2).
\f[I]NRDIM\f[] defaults to \f[B]1\f[], so that \f[B]\-s C 3 1\f[] is
equivalent to \f[B]\-s 3\f[].
\f[I]LIST\f[] is ignored.
.RS
.RE
.TP
.B M | manual
Manually specify a \f[I]LIST\f[] of pointers for \f[I]NRDIST\f[]
emission distributions and \f[I]NRDIM\f[] data dimensions
(\f[I]NRDIM\f[] must be set explicitely, even if it is \f[B]1\f[]).
The emission distribution for the d\-th dimension of the k\-th state is
the (k\f[I]NRDIM\f[] + d)\-th element in \f[I]LIST\f[] (all counts are
zero\-based), hence the length of \f[I]LIST\f[] must be a multiple of
\f[I]NRDIM\f[], its elements must be at least 0 and smaller than
\f[I]NRDIST\f[], and the number of states is the length of \f[I]LIST\f[]
divided by \f[I]NRDIM\f[].
.RS
.RE
.RE
.RE
.TP
.B \-e \f[I]DIST\f[] \f[I]PARAM\f[] | \-emissions \f[I]DIST\f[]
\f[I]PARAM\f[]
Set the emissions to be variates of a given \f[I]DIST\f[]ribution, and
let their parameters be sampled from priors using the given
hyper\f[I]PARAM\f[]eters.
The behavior of this option depends on the number of tokens: Let K be
the number of hyperparameters per prior, and D the number of emission
distributions (see \f[B]\-s\f[] option).
If \f[I]PARAM\f[] consists of K tokens, all priors are assumed to have
those same hyperparameters.
If there are N*K tokens, each prior gets its specific set of
hyperparameters.
In all other cases, an exception is thrown.
Arguments may take the following forms [Default: \f[B]normal\f[].
This means that \f[B]\-a\f[] has to be provided if \f[B]\-p\f[] is
not.]:
.RS
.TP
.B \f[B]normal\f[] [\f[I]PARAMs\f[]]
For Normal emissions, \f[I]PARAM\f[] is a collection of 4\-tuples
\f[I]ALPHA\f[] \f[I]BETA\f[] \f[I]MU\f[] \f[I]NU\f[], representing
parameters to the Normal\-Inverse Gamma distribution, sorted by state.
If \f[B]\-a\f[] is set, \f[I]PARAM\f[] is \f[I]VAR\f[] \f[I]P\f[]
instead, where \f[I]P\f[] is the probability to sample emission
variances less or equal than \f[I]VAR\f[]; if these parameters are not
provided, they default to \f[B]0.2 0.9\f[].
.RS
.RE
.PP
\f[I]NOTE\f[]: No other emission type than Normal is currently
supported.
.PP
If neither \f[B]\-a\f[] nor \f[I]PARAM\f[] is provided, an exception is
thrown.
.RE
.TP
.B \-a | \-auto\-priors
Use automatic hyperparameters for emission priors, based on the wavelet
transform of the data.
This changes the meaning of parameters passed to \f[B]\-p\f[].
.RS
.RE
.TP
.B \-t \f[I]VALUES\f[] | \-transitions \f[I]VALUES\f[]
Parameters for transition probabilities.
These are the parameters alpha for a Dirichlet distribution.
\f[I]VALUES\f[] can take the following forms:
.RS
.TP
.B \f[I]ALPHA\f[]
A single number means that all alpha\-parameters are set to the same
value.
.RS
.RE
.TP
.B \f[I]SELF\f[] \f[I]TRANS\f[]
All alphas corresponding to self\-transitions are set to \f[I]SELF\f[],
the others to \f[I]TRANS\f[].
.RS
.RE
.RE
.TP
.B \-S | \-no\-self\-transitions
Do not use self\-transition probabilities within blocks (this has no
effect for mixture sampling).
.RS
.RE
.TP
.B \-I \f[I]ALPHA\f[] | \-initial \f[I]ALPHA\f[]
Sets the alpha parameter of the Dirichlet distribution used as a prior
for the initial state distribution.
.RS
.RE
.SS SAMPLING SCHEME
.TP
.B \-R | \-random\-seed
An unsigned integer value to be used to seed the random number
generator.
If \f[B]\-R\f[] is not set, a seed is generated from the current epoch
time.
A seed should be set manually using \f[B]\-R\f[] whenever
reproducibility is required.
.RS
.RE
.TP
.B \-i \f[I]SCHEME\f[] ... | \-iterations \f[I]SCHEME\f[] ...
A list of sampling \f[I]SCHEME\f[]s, each of which consists of either a
single token \f[I]FLAG\f[], or three tokens, \f[I]TYPE\f[] \f[I]ITER\f[]
\f[I]THIN\f[].The following \f[I]FLAG\f[]s can be used:
.RS
.TP
.B P
Sample from priors.
Since the very first action in a Gibbs sampler is a sampling from the
prior, an additional \f[B]P\f[] is always silently prepended to
\f[B]\-i\f[].
.RS
.RE
.TP
.B S
Set compression to \f[I]static\f[], the block structure is determined by
the current state of emission parameters and remains unchanged until
\f[B]D\f[] is provided.
.RS
.RE
.TP
.B D
Set compression to \f[I]dynamic\f[], the block structure changes at
every iteration based on ht current state of emission parameters and
remains unchanged unto \f[B]D\f[] is provided.
.RS
.RE
.PP
The following triples can be used:
.IP "1." 3
The \f[I]TYPE\f[] of sampling method to be used is one of the following:
.RS 4
.TP
.B M
\f[I]Mixture sampling\f[] treats compression as a way to impose equality
relations on otherwise exchangeable data points.
It completely ignores transition probabilities passed to the model, and
instead assumes transitions to be implied in the block structure alone.
This is much faster than the other methods, as it depends linearly on
the number of states, but is not truly an HMM.
High\-variance components are prone to oversegmentation, and spurious
differences in sampled values can lead to segments which come from the
same true state being assigned to different states.
However, if the variance is expected to be similar over all states, this
variant can yield reasonably good results very fast.
.RS
.RE
.TP
.B F
\f[I]Forward\-Backward Gibbs sampling\f[] uses a dynamic programming
trellis to quickly sample state sequences unaffected by
auto\-correlation due to adjacent blocks.
FBG is considered the state\-of\-the\-art for Gibbs sampling in HMM.
Running times depends quadratically on the number of states.
.RS
.RE
.RE
.IP "2." 3
The number of sampling \f[I]ITER\f[]ations.
.IP "3." 3
The type of \f[I]THIN\f[]ning to be used to record sampled state
sequences (0=record none, 1=record all, 2=record every second sample,
etc.).
.PP
[Default: \f[B]M 500 0 S P F 200 0 F 300 3\f[].
Under this scheme, 100 unrecorded mixture iterations are performed to
converge to a block structure, which is then fixed.
The emission parameters are resampled from the prior so as to remove the
influence of the mixture observations, and 200 FBG iterations for
burn\-in are performed, followed by 300 FBG iterations, every third of
which is recorded, resulting in 100 recorded iterations.]
.RE
.SS COMPRESSION
.TP
.B \-m \f[I]FLOAT\f[] | \-weight\-multiplier \f[I]FLOAT\f[]
Multiply weights by this factor, to avoid overcompression.
[Default: \f[B]1.0\f[]]
.RS
.RE
.SH CAVEATS
.PP
While HaMMLET is designed to minimize memory consumption (univariate
models of 100 million data points can be handled on a standard laptop),
one should still be aware that the size of the marginal state records
and the trellis cannot be predicted before running the inference.
As a consequence, data that only allows for low compression ratios may
still incur huge memory overhead, as it negates the central approach
that makes FBG feasible on such scales.
If memory consumption gets out of hand, you might want to try increasing
the number of burn\-in steps; if the sampler has not fully converged,
individual iterations might have very low compression, even though the
data itself would allow for better ratios.
Likewise, decreasing the number of states might be an option, since
superfluous state parameters will be sampled solely from the prior and
yield arbitrarily low noise variances.
If this does not work, using Mixture model sampling might be an option,
but results should be interpreted with care, see \f[B]\-i\f[] option.
.PP
Though the model should work for any emission distribution in the
exponential family (Normal, Poisson, Exponential, Laplace, Gamma,
Chi\-Squared etc.), only Normal emissions are implemented at the moment.
.PP
Multivariate models are supported in the sense that multiple data
dimensions may share their generating parameters.
True multivariate models such as Normals with non\-diagonal covariance
matrix are not yet supported.
.PP
Plotting the results is done using external Python libraries (NumPy,
Matplotlib).
As these are not optimized for large\-scale applications, this can take
a long time, often longer than the inference itself.
.PP
HaMMLET does not support the convention of combining single\-letter
options, such as replacing \f[B]\-x \-y \-z\f[] by \f[B]\-xyz\f[].
.SH HISTORY
.PP
The first version of HaMMLET was developed by Eric Brugel and John
Wiedenhoeft, and published in 2016 in PLOS CompBio and RECOMB.
It used a wavelet tree data structure for dynamic compression.
The current version is designed for minimal memory footprint in
large\-scale applications.
Changes include: a breakpoint array data structure for optimal wavelet
compression, an in\-place algorithm for its construction,
run\-length\-encoded output, and a queue\-based implementation to record
run\-length\-encoded state sequences.
It is currently developed and maintained by John Wiedenhoeft (ORCID:
0000\-0002\-6935\-1517 (https://orcid.org/0000-0002-6935-1517)) at
<https://github.com/wiedenhoeft/HaMMLET>.
.SH REPORTING BUGS
.PP
GitHub issue tracking system:
<https://github.com/wiedenhoeft/HaMMLET/issues>
.SH SEE ALSO
.PP
Current hosting site: <https://wiedenhoeft.github.io/HaMMLET/>
.PP
Current repository: <https://github.com/wiedenhoeft/HaMMLET>
.PP
Stable link: <https://schlieplab.org/Software/HaMMLET/>
.PP
Documentation in different formats (pdf, html, txt, man) can be found in
the doc/ subfolder of HaMMLET\[aq]s installation directory.
.PP
.PP
.ce
┏━━━━━┓     ┏━━━━━┓ 
.ce
┣━━━━━┫     ┃ ┏━━━┫
.ce
┃ ┏━━━┫     ┃ ┃ ┏━┫
.ce
┃ ┃ ┏━┻━━━━━┫ ┃ ┃ ┃
.ce
┃ ┃ ┃ ┏━━━━━┫ ┃ ┃ ┃
.ce
┃ ┃ ┃ ┣━━━━━┛ ┃ ┃ ┃
.ce
┃ ┃ ┃ ┣━━━━━┳━┛ ┃ ┃
.ce
┣━┛ ┃ ┃     ┣━━━┛ ┃
.ce
┣━━━┛ ┃     ┣━━━━━┫
.ce
┗━━━━━┛     ┗━━━━━┛ 
