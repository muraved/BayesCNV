.\" Automatically generated by Pandoc 1.16.0.2
.\"
.ad l
.TH "HaMMLET" "1" "" "" ""
.hy
.SH NAME
.PP
\f[B]HaMMLET\f[] \- Fast Bayesian Inference for Hidden Markov Models
using Dynamic Haar Wavelet Compression.
.SH DESCRIPTION
.PP
HaMMLET is a fast Forward\-Backward Gibbs (FBG) sampler for Bayesian
HMM.
It also implements alternative sampling schemes (currently supported:
Mixture Model sampling).
Given numerical input data and prior parameters, it outputs a full
distribution of latent HMM states for each position, integrating over
the entire parameter space.
In modern applications, such as the detection of copy\-number variants
(CNV) using whole\-genome sequencing data, the input sizes are on the
order of millions to billions of data points.
To avoid prohibitively long running times and slow convergence, HaMMLET
uses the Haar wavelet transform to dynamically compress the data into
blocks of sufficient statistics, based on the lowest noise estimate in
each iteration of the Gibbs sampler.
.PP
When using HaMMLET, please cite the following paper:
.RS
.PP
Wiedenhoeft, J., Brugel, E., & Schliep, A.
(2016).
"Fast Bayesian Inference of Copy Number Variants using Hidden Markov
Models with Wavelet Compression".
PLOS Computational Biology, 12(5), e1004871.
http://doi.org/10.1371/journal.pcbi.1004871.
This paper was selected for oral presentation at RECOMB 2016.
.RE
.SH USAGE EXAMPLE
.PP
\f[B]hammlet \ \-f data.csv \ \-o hmm/result_ .csv \ \-O blocks
compression \ \-s C 3 2 \ \-i M 100 0 F 200 5 \ \-a \ \-t 10 1\f[]
.PP
This reads data from \f[B]data.csv\f[], and writes state marginals to
\f[B]hmm/result_\f[]marginals\f[B]\&.csv\f[] (notice the space, \-o
takes two arguments!).
It also outputs the sizes of \f[B]blocks\f[] for each iteration to
hmm/result_\f[B]blocks\f[].csv, and \f[B]compression\f[] ratios to
hmm/result_\f[B]compression\f[].csv.
There are 9 hidden states in total, resulting from all possible
\f[B]combinations\f[] of \f[B]3\f[] emission distributions to generating
\f[B]2\f[]\-dimensional data.
Sampling of state sequences is done by first running \f[B]mixture
sampling\f[] for \f[B]100\f[] iterations, \f[B]none\f[] of which is
recorded, followed by \f[B]FBG\f[] for \f[B]200\f[] iterations,
recording every \f[B]fifth\f[] of them.
This is done using \f[B]automatic\f[] emission priors with standard
parameters.
Prior \f[B]transition\f[] weights are \f[B]10\f[] for self\-transitions,
and \f[B]1\f[] for transition between different states.
.SH OPTIONS
.TP
.B \-h | \-help
Display a friendly help message.
.RS
.RE
.TP
.B \-v | \-verbose
Print information to \f[I]STDOUT\f[] during run\-time.
.RS
.RE
.TP
.B \-g | \-arguments
Print arguments.
For each flag, print an asterisk if it was set by the user, as well as
the parameters being used.
If the flag was not set, these are the default parameters.
.RS
.RE
.SS INPUT AND OUTPUT
.PP
HaMMLET reads the observed emission values as a stream of
whitespace\-separated numeric values from \f[I]STDIN\f[], unless
\f[B]\-f\f[] is specified.
Linebreaks are treated as whitespace, and no formatting such as CSV is
interpreted.
For multivariate models, the dimensions of each position are filled in
increasing order, after which dimensions for the next position are
filled.
If the number of input values is not a multiple of the number of
dimensions (see \f[B]\-s\f[] option), an exception is thrown.
.PP
The output consists of a CSV file representing a run\-length encoded
version of the state marginals.
The first column represents the length of a segment (number of input
positions), and subsequent columns represent the recorded counts for
each state, in increasing order of state number.
.TP
.B \-f \f[I]FILE\f[] | \-input\-file \f[I]FILE\f[]
Read input data from \f[I]FILE\f[] instead of \f[I]STDIN\f[].
.RS
.RE
.TP
.B \-o \f[I]PREFIX\f[] | \-output\-prefix \f[I]PREFIX\f[]
The prefix for the output file paths.
\f[I]PREFIX\f[] is extended by a short description and an appropriate
file extension to yield an output file name, such as
\f[I]PREFIX\f[]marginals.csv for the file containing the marginal state
distribution; for additional files, see the \f[B]\-O\f[] option for
details.
Existing files are silently overwritten.
[Default: \f[B]hammlet\f[]]
.RS
.RE
.TP
.B \-O \f[I]TYPE\f[] ... | \-output\-data \f[I]TYPE\f[] ...
Specify a list of data types to be output in addition to the marginals.
This only applies to recorded iterations as specified using
\f[B]\-i\f[].
It may contain any of the following:
.RS
.TP
.B S | sequences
Output each state sequence individually, one per line, separated by
whitespace, using run\-length encoding of the form
\f[I]LENGTH\f[]:\f[I]STATE\f[].
.RS
.RE
.TP
.B P | parameters
Output the emission parameters for each state in increasing order of
state number, separated by tabs.
.RS
.RE
.TP
.B B | blocks
Output the block structure (sizes of all blocks) created by dynamic
compression, separated by whitespace.
.RS
.RE
.TP
.B C | compression
Output the compression ratio for each iteration.
.RS
.RE
.TP
.B G | segments
Output the number of segments in each iteration, as well as the number
of values used to store the compressed marginals (for diagntic
purposes).
.RS
.RE
.RE
.TP
.B \-w | \-overwrite
Overwrite existing output files.
If \f[B]\-w\f[] is not provided and an output file already exists, an
exception is thrown.
.RS
.RE
.SS MODEL SPECIFICATIONS
.TP
.B \-s \f[I]PARAM\f[] | \-states \f[I]PARAM\f[]
Definition of hidden states.
\f[I]PARAM\f[] may take the following forms [Default: \f[B]3\f[]]:
.RS
.TP
.B \f[I]NRSTATES\f[]
The typical, simple case of an HMM: Given a single unsigned integer
\f[I]NRSTATES\f[], the data is assumed to be one\-dimensional and
generated from this many hidden states.
.RS
.RE
.TP
.B \f[I]MAPPING\f[] \f[I]NRPARAM\f[] [\f[I]NRDIM\f[]]
State definitions in the form of a \f[I]MAPPING\f[].
The data has \f[I]NRDIM\f[] dimensions, and there are \f[I]NRPARAM\f[]
different emission distributions.
If \f[I]NRDIM\f[] is not provided, it defaults to \f[B]1\f[].
A state is defined as a vector S of size \f[I]NRDIM\f[], where S[i]
denotes that the i\-th dimension of an emission sampled from this state
was generated from the S[i]\-th emission distribution.
For instance, if a 3\-dimensional data point is assigned to a state with
mapping S=[1 1 2], its first two dimensions are assumed to be generated
by emission distribution 1, and its third dimension by emission
distribution 2.
The following \f[I]MAPPING\f[] schemes are supported:
.RS
.TP
.B C | combination
States express all possible combinations of emission distributions,
resulting in \f[I]NRPARAMS\f[]^\f[I]NRDIM\f[] different states.
For instance, \f[B]\-s C 2 3\f[] generates 2^3=8 state mappings: (1 1
1), (1 1 2), (1 2 1), (1 2 2), (2 1 1), (2 1 2), (2 2 1), and (2 2 2).
Note that \f[B]\-s C 3 1\f[] is equivalent to \f[B]\-s 3\f[].
.RS
.RE
.PP
\f[I]NOTE\f[]: No other mapping schemes are currently supported.
.RE
.RE
.TP
.B \-e \f[I]DIST\f[] \f[I]PARAM\f[] | \-emissions \f[I]DIST\f[] \f[I]PARAM\f[]
Set the emissions to be variates of a given \f[I]DIST\f[]ribution, and
let their parameters be sampled from priors using the given
hyper\f[I]PARAM\f[]eters.
The behavior of this option depends on the number of tokens: Let K be
the number of hyperparameters per prior, and D the number of emission
distributions (see \f[B]\-s\f[] option).
If \f[I]PARAM\f[] consists of K tokens, all priors are assumed to have
those same hyperparameters.
If there are N*K tokens, each prior gets its specific set of
hyperparameters.
In all other cases, an exception is thrown.
Arguments may take the following forms [Default: \f[B]normal\f[].
This means that \f[B]\-a\f[] has to be provided if \f[B]\-p\f[] is
not.]:
.RS
.TP
.B \f[B]normal\f[] [\f[I]PARAMs\f[]]
For Normal emissions, \f[I]PARAM\f[] is a collection of 4\-tuples
\f[I]ALPHA\f[] \f[I]BETA\f[] \f[I]MU\f[] \f[I]NU\f[], representing
parameters to the Normal\-Inverse Gamma distribution, sorted by state.
If \f[B]\-a\f[] is set, \f[I]PARAM\f[] is \f[I]VAR\f[] \f[I]P\f[]
instead, where \f[I]P\f[] is the probability to sample emission
variances less or equal than \f[I]VAR\f[]; if these parameters are not
provided, they default to \f[B]0.2 0.9\f[].
.RS
.RE
.PP
\f[I]NOTE\f[]: No other emission type than Normal is currently
supported.
.PP
If neither \f[B]\-a\f[] nor \f[I]PARAM\f[] is provided, an exception is
thrown.
.RE
.TP
.B \-a | \-auto\-priors
Use automatic hyperparameters for emission priors, based on the wavelet
transform of the data.
This changes the meaning of parameters passed to \f[B]\-p\f[].
.RS
.RE
.TP
.B \-t \f[I]VALUES\f[] | \-transitions \f[I]VALUES\f[]
Parameters for transition probabilities.
These are the parameters alpha for a Dirichlet distribution.
\f[I]VALUES\f[] can take the following forms:
.RS
.TP
.B \f[I]ALPHA\f[]
A single number means that all alpha\-parameters are set to the same
value.
.RS
.RE
.TP
.B \f[I]SELF\f[] \f[I]TRANS\f[]
All alphas corresponding to self\-transitions are set to \f[I]SELF\f[],
the others to \f[I]TRANS\f[].
.RS
.RE
.RE
.TP
.B \-S | \-no\-self\-transitions
Do not use self\-transition probabilities within blocks (this has no
effect for mixture sampling).
.RS
.RE
.TP
.B \-I \f[I]ALPHA\f[] | \-initial \f[I]ALPHA\f[]
Sets the alpha parameter of the Dirichlet distribution used as a prior
for the initial state distribution.
.RS
.RE
.SS SAMPLING SCHEME
.TP
.B \-R | \-random\-seed
An unsigned integer value to be used to seed the random number
generator.
If \f[B]\-R\f[] is not set, a seed is generated from the current epoch
time.
A seed should be set manually using \f[B]\-R\f[] whenever
reproducibility is required.
.RS
.RE
.TP
.B \-i \f[I]SCHEME\f[] ... | \-iterations \f[I]SCHEME\f[] ...
A list of sampling \f[I]SCHEME\f[]s, each of which consists of three
tokens, \f[I]TYPE\f[] \f[I]ITER\f[] \f[I]THIN\f[]:
.RS
.IP "1." 3
The \f[I]TYPE\f[] of sampling method to be used is one of the following:
.RS 4
.TP
.B F
\f[I]Forward\-Backward Gibbs sampling\f[] uses a dynamic programming
trellis to quickly sample state sequences unaffected by
auto\-correlation due to adjacent blocks.
FBG is considered the state\-of\-the\-art for Gibbs sampling in HMM.
Running times depends quadratically on the number of states.
.RS
.RE
.TP
.B M
\f[I]Mixture sampling\f[] treats compression as a way to impose equality
relations on otherwise exchangeable data points.
It completely ignores transition probabilities passed to the model, and
instead assumes transitions to be implied in the block structure alone.
This is much faster than the other methods, as it depends linearly on
the number of states, but is not truly an HMM.
High\-variance components are prone to oversegmentation, and spurious
differences in sampled values can lead to segments which come from the
same true state being assigned to different states.
However, if the variance is expected to be similar over all states, this
variant can yield reasonably good results very fast.
.RS
.RE
.RE
.IP "2." 3
The number of sampling \f[I]ITER\f[]ations.
.IP "3." 3
The type of \f[I]THIN\f[]ning to be used to record sampled state
sequences (0=record none, 1=record all, 2=record every second sample,
etc.).
.PP
If the total number of tokens provided to \f[B]\-i\f[] is not a multiple
of 3, an exception is thrown.
[Default: \f[B]M 100 0 F 250 10\f[], i.e.\ an unrecorded burn\-in of 100
mixture iterations, followed by 250 FBG iterations with thinning factor
10, resulting in 25 recorded state sequences.]
.RE
.SS COMPRESSION
.TP
.B \-b \f[I]MIN\f[] \f[I]MAX\f[] | \-block\-limits \f[I]MIN\f[] \f[I]MAX\f[]
The minimum and maximum block size allowed during compression.
0 means no limit.
[Default: \f[B]0 0\f[]]
.RS
.RE
.TP
.B \-m \f[I]FLOAT\f[] | \-weight\-multiplier \f[I]FLOAT\f[]
Multiply weights by this factor, to avoid overcompression.
[Default: \f[B]1.0\f[]]
.RS
.RE
.SH CAVEATS
.PP
While HaMMLET is designed to minimize memory consumption (univariate
models of 100 million data points can be handled on a standard laptop),
one should still be aware that the size of the marginal state records
and the trellis cannot be predicted before running the inference.
As a consequence, data that only allows for low compression ratios may
still incur huge memory overhead, as it negates the central approach
that makes FBG feasible on such scales.
If memory consumption gets out of hand, you might want to try increasing
the number of burn\-in steps; if the sampler has not fully converged,
individual iterations might have very low compression, even though the
data itself would allow for better ratios.
Likewise, decreasing the number of states might be an option, since
superfluous state parameters will be sampled solely from the prior and
yield arbitrarily low noise variances.
If this does not work, using Mixture model sampling might be an option,
but results should be interpreted with care, see \f[B]\-i\f[] option.
.PP
Though the model should work for any emission distribution in the
exponential family (Normal, Poisson, Exponential, Laplace, Gamma,
Chi\-Squared etc.), only Normal emissions are implemented at the moment.
.PP
Multivariate models are supported in the sense that multiple data
dimensions may share their generating parameters.
True multivariate models such as Normals with non\-diagonal covariance
matrix are not yet supported.
.PP
Plotting the results is done using external Python libraries (NumPy,
Matplotlib).
As these are not optimized for large\-scale applications, this can take
a long time, often longer than the inference itself.
.PP
HaMMLET does not support the convention of combining single\-letter
options, such as replacing \f[B]\-x \-y \-z\f[] by \f[B]\-xyz\f[].
.SH HISTORY
.PP
The first version of HaMMLET was developed by Eric Brugel and John
Wiedenhoeft, and published in 2016 in PLOS CompBio and RECOMB.
It used a wavelet tree data structure for dynamic compression.
The current version is designed for minimal memory footprint in
large\-scale applications.
Changes include: a breakpoint array data structure for optimal wavelet
compression, an in\-place algorithm for its construction,
run\-length\-encoded output, and a queue\-based implementation to record
run\-length\-encoded state sequences.
It is currently developed and maintained by John Wiedenhoeft (ORCID:
0000\-0002\-6935\-1517 (https://orcid.org/0000-0002-6935-1517)) at
<https://github.com/wiedenhoeft/HaMMLET>.
.SH REPORTING BUGS
.PP
GitHub issue tracking system:
<https://github.com/wiedenhoeft/HaMMLET/issues>
.SH SEE ALSO
.PP
Current hosting site: <https://wiedenhoeft.github.io/HaMMLET/>
.PP
Current repository: <https://github.com/wiedenhoeft/HaMMLET>
.PP
Stable link: <https://schlieplab.org/Software/HaMMLET/>
.PP
Documentation in different formats (pdf, html, txt, man) can be found in
the doc/ subfolder of HaMMLET\[aq]s installation directory.
